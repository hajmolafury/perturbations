{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPJX-M74ioow",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yh0rjUSMjJAv",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "seed=0\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train_data, y_train_cold),(x_test_data,y_test_cold) = mnist.load_data()\n",
    "x_train_data, x_test_data = x_train_data / 255.0, x_test_data / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESirBBgVkVha",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_train = sess.run(tf.one_hot(y_train_cold,10))\n",
    "    y_test =  sess.run(tf.one_hot(y_test_cold,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QdQWRR7vfB_",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_train=[]\n",
    "x_test=[]\n",
    "\n",
    "n_train = len(x_train_data)\n",
    "n_test = len(x_test_data)\n",
    "\n",
    "for i in range(len(x_train_data)):\n",
    "    x_train.append(np.ndarray.flatten(x_train_data[i]))\n",
    "    \n",
    "for i in range(len(x_test_data)):\n",
    "    x_test.append(np.ndarray.flatten(x_test_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1547819972545,
     "user": {
      "displayName": "Yash Mehta",
      "photoUrl": "https://lh5.googleusercontent.com/-Co0YSLq7WUQ/AAAAAAAAAAI/AAAAAAAAL14/de_Tazr353o/s64/photo.jpg",
      "userId": "01363125706256879103"
     },
     "user_tz": 0
    },
    "id": "HmTgwQFwmLK-",
    "outputId": "838b6d62-12ed-4f5d-92ad-8eadd3f462ef",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,[n_train,784])\n",
    "x_test = np.reshape(x_test,[n_test, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sigma=0.001\n",
    "batch_size=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def build_graph(n_hl, update_rule, num_hidden_layers):\n",
    "    #later can include passing non-linearity in the function as well!\n",
    "    #include dataset independence while creating the graph & separate function for loading data!\n",
    "    #different function to create all the variables & operations!\n",
    "    g=tf.Graph()\n",
    "    with g.as_default():        \n",
    "        # init=tf.global_variables_initializer()\n",
    "        \n",
    "        X = tf.placeholder(dtype=tf.float32, shape=[None, 784], name='x')\n",
    "        Y = tf.placeholder(dtype=tf.float32, shape=[None,10], name='y')\n",
    "        \n",
    "        xavier = tf.contrib.layers.xavier_initializer(seed=0)\n",
    "        \n",
    "        w={}\n",
    "        b={}\n",
    "        h={}\n",
    "        x={}\n",
    "        s={}\n",
    "        h_star={}\n",
    "        x_star={}\n",
    "        del_h={}\n",
    "        delta_w={}\n",
    "        delta_b={}\n",
    "        \n",
    "        update_w={}\n",
    "        update_b={}\n",
    "        \n",
    "        s['in']=tf.zeros([1], dtype=tf.float32, name='s_in')\n",
    "        for i in range(num_hidden_layers+1):\n",
    "            s[str(i)]=tf.zeros([1], dtype=tf.float32, name='s_'+str(i))\n",
    "            \n",
    "        for i in range(num_hidden_layers+1):\n",
    "            if(i==0):\n",
    "                w[str(i)]=tf.Variable(xavier([n_hl, 784]))\n",
    "                b[str(i)]=tf.Variable(xavier([n_hl]))\n",
    "                h[str(i)]=tf.matmul(X, tf.transpose(w[str(i)]))\n",
    "                x[str(i)]=tf.nn.relu(tf.add(h[str(i)], b[str(i)]))\n",
    "                if(update_rule=='np' or update_rule=='np-hybrid'):\n",
    "                    s[str(i)]=tf.random_normal(shape = [batch_size,n_hl], mean=0, stddev=sigma, dtype=tf.float32, name='s_'+str(i), seed=seed)\n",
    "                if(update_rule=='ip'):\n",
    "                    s['in']=tf.random_normal(shape = [batch_size,784], mean=0, stddev=sigma, dtype=tf.float32, name='s_in', seed=seed)\n",
    "                    \n",
    "            elif (i<num_hidden_layers):\n",
    "                w[str(i)]=tf.Variable(xavier([n_hl, n_hl]))\n",
    "                b[str(i)]=tf.Variable(xavier([n_hl]))\n",
    "                h[str(i)]=tf.matmul(x[str(i-1)], tf.transpose(w[str(i)]))\n",
    "                x[str(i)]=tf.nn.relu(tf.add(h[str(i)], b[str(i)]))\n",
    "                if(update_rule=='np' or update_rule=='np-hybrid'):\n",
    "                    s[str(i)]=tf.random_normal(shape = [batch_size,n_hl], mean=0, stddev=sigma, dtype=tf.float32, name='s_'+str(i), seed=seed)\n",
    "            else:\n",
    "                w[str(i)]=tf.Variable(xavier([10, n_hl]))\n",
    "                b[str(i)]=tf.Variable(xavier([10]))\n",
    "                h[str(i)]=tf.matmul(x[str(i-1)], tf.transpose(w[str(i)]))\n",
    "                pred=tf.nn.softmax(tf.add(h[str(i)], b[str(i)]))\n",
    "                if(update_rule=='np' or update_rule=='np-hybrid'):\n",
    "                    s[str(i)]=tf.random_normal(shape = [batch_size, 10], mean=0, stddev=sigma, dtype=tf.float32, name='s_'+str(i), seed=seed)\n",
    "                               \n",
    "        lr = tf.Variable(xavier([1]) , dtype=tf.float32, name='lr')\n",
    "        \n",
    "        error=tf.reduce_mean(np.square(pred-Y),1)\n",
    "        mse=tf.losses.mean_squared_error(predictions=pred, labels=Y)\n",
    "        \n",
    "        if(update_rule=='ip' or update_rule=='np' or update_rule=='np-hybrid'):    \n",
    "            for i in range(num_hidden_layers+1):\n",
    "                if(i==0):                               \n",
    "                    h_star[str(i)]=tf.matmul(tf.add(X,s['in']), tf.transpose(w[str(i)]))    \n",
    "                else:\n",
    "                    h_star[str(i)]=tf.matmul(x_star[str(i-1)], tf.transpose(w[str(i)]))    \n",
    "                \n",
    "                if(i<num_hidden_layers):                \n",
    "                    x_star[str(i)]=tf.nn.relu(tf.add(tf.add(h_star[str(i)], b[str(i)]), s[str(i)]))\n",
    "                    \n",
    "                else:\n",
    "                    pred_star=tf.nn.softmax(tf.add(tf.add(h_star[str(i)], b[str(i)]), s[str(i)]))\n",
    "            \n",
    "            error_star=tf.reduce_mean(np.square(pred_star-Y),1)\n",
    "            var = sigma ** 2\n",
    "            k = -lr * (error_star - error) / var\n",
    "        \n",
    "            for i in range(num_hidden_layers+1):\n",
    "                if(update_rule=='ip'):\n",
    "                    del_h[str(i)]=h_star[str(i)]-h[str(i)]\n",
    "    \n",
    "                elif(update_rule=='np'):\n",
    "                    del_h[str(i)]=s[str(i)]\n",
    "                \n",
    "                elif(update_rule=='np-hybrid'):\n",
    "                    del_h[str(i)]=s[str(i)]\n",
    "                    k=k*(1-alpha)\n",
    "                    \n",
    "                    \n",
    "                if(i==0):\n",
    "                    delta_w[str(i)]=tf.einsum('ki,kj->kij', del_h[str(i)], X)\n",
    "                \n",
    "                else:\n",
    "                    delta_w[str(i)]=tf.einsum('ki,kj->kij', del_h[str(i)], x[str(i-1)])\n",
    "                    \n",
    "                delta_w[str(i)]=tf.einsum('kij,k->kij',delta_w[str(i)],k)\n",
    "                delta_w[str(i)]=tf.reduce_mean(delta_w[str(i)],0)\n",
    "                delta_b[str(i)]=tf.einsum('ki,k->ki',del_h[str(i)],k)\n",
    "                delta_b[str(i)]=tf.reduce_mean(delta_b[str(i)],0)\n",
    "                \n",
    "                update_w[str(i)]=tf.assign(w[str(i)], tf.add(w[str(i)],delta_w[str(i)]), name='update_w'+str(i))         \n",
    "                update_b[str(i)]=tf.assign(b[str(i)], tf.add(b[str(i)],delta_b[str(i)]), name='update_b'+str(i))\n",
    "         \n",
    "        change_lr=tf.assign(lr, tf.reshape(learning_rate, [1]), name='change_lr')\n",
    "                \n",
    "        if(update_rule=='np-hybrid'):\n",
    "            optimizer=tf.train.GradientDescentOptimizer(learning_rate=alpha*lr[0], name='optimizer').minimize(mse)\n",
    "        elif(update_rule=='sgd'):\n",
    "            optimizer=tf.train.GradientDescentOptimizer(learning_rate=lr[0], name='optimizer').minimize(mse)\n",
    "        # train_step=optimizer.minimize(mse, name='train_step')\n",
    "\n",
    "        is_correct = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "        accuracy = 100*tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "        tf.identity(accuracy, 'accuracy')\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "outputs": [],
   "source": [
    "def find_acc(which_acc):\n",
    "    acc=[]\n",
    "    if(which_acc=='test'):\n",
    "        acc.append(sess.run('accuracy:0', feed_dict={'x:0':x_test, 'y:0':y_test}))\n",
    "\n",
    "    elif(which_acc=='train'):\n",
    "        n=int(n_train/n_test)\n",
    "        for i in range(n):\n",
    "            acc.append(sess.run('accuracy:0', feed_dict={'x:0':x_train[i*n_test:(i+1)*n_test], 'y:0':y_train[i*n_test:(i+1)*n_test]}))\n",
    "    else:\n",
    "        print('wrong accuracy requested!!')\n",
    "    return np.mean(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_acc():    \n",
    "    train_acc.append(find_acc('train'))\n",
    "    test_acc.append(find_acc('test'))\n",
    "    print('epoch : ', i+1, '  test_acc : ', test_acc[-1])\n",
    "    sec=int(time.time()-start)\n",
    "    print(int(sec/60),'m ', int(sec%60),'s')\n",
    "    \n",
    "    return test_acc[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_network(num_hidden_layers):\n",
    "    for j in range(int(n_train/batch_size)):\n",
    "        ind = np.random.randint(0, n_train, size=(batch_size))\n",
    "        \n",
    "        if(update_rule=='sgd' or update_rule=='np-hybrid'):\n",
    "            ops=['optimizer']\n",
    "            sess.run(ops, feed_dict = {'x:0':x_train[ind], 'y:0':y_train[ind]})\n",
    "            \n",
    "        if(update_rule=='ip' or update_rule=='np' or update_rule=='np-hybrid'):\n",
    "            updates=[]\n",
    "            squiggles=[]\n",
    "            for i in range(num_hidden_layers+1):\n",
    "                updates.append('update_w'+str(i)+':0')\n",
    "                updates.append('update_b'+str(i)+':0')\n",
    "                squiggles.append('s_'+str(i)+':0')\n",
    "            \n",
    "            ops=[squiggles, updates]\n",
    "            sess.run(ops, feed_dict = {'x:0':x_train[ind], 'y:0':y_train[ind]})\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_in_file():\n",
    "    row=test_acc\n",
    "    with open('hybrid-test.csv', 'a') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerow(row)\n",
    "    \n",
    "    csvFile.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs=5\n",
    "interval=1\n",
    "\n",
    "hl_size = 300\n",
    "learning_rate = 0.1\n",
    "num_hidden_layers=1\n",
    "test_acc=[]\n",
    "train_acc=[]\n",
    "update_rule='np-hybrid'\n",
    "alpha=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "TRAINING :  300  hidden units \nlearning rate :  [0.1] \n\nepoch :  1   test_acc :  9.56\n0 m  0 s\n",
      "epoch :  2   test_acc :  17.720001\n0 m  2 s\n",
      "epoch :  3   test_acc :  38.280003\n0 m  4 s\n",
      "epoch :  4   test_acc :  52.569996\n0 m  5 s\n",
      "epoch :  5   test_acc :  58.56\n0 m  7 s\n",
      "TOTAL TIME :  0 m  9 s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)\n",
    "graph=build_graph(hl_size, update_rule, num_hidden_layers)\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run('change_lr:0')\n",
    "    print('TRAINING : ', hl_size,' hidden units', '\\nlearning rate : ', sess.run('lr:0'), '\\n')\n",
    "    for i in range(n_epochs):\n",
    "        if i%interval==0:\n",
    "            if(print_acc()>98):\n",
    "                break\n",
    "            if i>10 and find_acc('test')<15:\n",
    "                break    \n",
    "                \n",
    "        train_network(num_hidden_layers)\n",
    "    \n",
    "    sess.close()\n",
    "    # write_in_file()\n",
    "\n",
    "sec=int(time.time()-start)\n",
    "print('TOTAL TIME : ', int(sec/60),'m ', int(sec%60),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%            \n"
    }
   },
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(8, 5.5))\n",
    "# xx=np.arange(0,n_epochs, interval)\n",
    "# ax1.set_xlabel('epochs')\n",
    "# ax1.set_ylabel('accuracy')\n",
    "# ax1.plot(xx, test_acc, color='tab:red', label='test accuracy')\n",
    "# ax1.plot(xx, train_acc, color='tab:blue', label='training accuracy')\n",
    "# ax1.legend()\n",
    "# \n",
    "# axes = plt.gca()\n",
    "# \n",
    "# ax1.set_facecolor(\"#ffffb3\")\n",
    "# \n",
    "# ax1.annotate(str(round(test_acc[-1],1)),xy=(xx[-1]-0.5,test_acc[-1]+0.7), color='tab:red')\n",
    "# ax1.annotate(str(round(train_acc[-1],1)),xy=(xx[-1]-0.5,train_acc[-1]-2.2), color='tab:blue')\n",
    "# \n",
    "# plt.grid(True, color=\"#93a1a1\", alpha=0.3)\n",
    "# plt.show()\n",
    "# plt.savefig('plot1.svg', dpi=500)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "np_mnist_linear_regression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}